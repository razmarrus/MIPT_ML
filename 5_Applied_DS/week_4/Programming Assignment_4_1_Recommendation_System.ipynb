{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23504409",
   "metadata": {},
   "source": [
    "# Programming Assignment: \n",
    "\n",
    "\n",
    "1. На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)\n",
    "2. Реализуйте два алгоритма рекомендаций:\n",
    "\n",
    "    сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    "    сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    "\n",
    "3. Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие?           Обратите внимание на различие качества на обучающей и тестовой           выборке в случае рекомендаций по частотам покупки.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0d1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "import collections\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f7d67",
   "metadata": {},
   "source": [
    "\n",
    "**Входные данные**\n",
    "\n",
    "Вам дается две выборки с пользовательскими сессиями - id-шниками просмотренных и id-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: id просмотренных товаров через , затем идёт ; после чего следуют id купленных товаров (если такие имеются), разделённые запятой. Например, 1,2,3,4; или 1,2,3,4;5,6.\n",
    "\n",
    "Гарантируется, что среди id купленных товаров все различные.\n",
    "\n",
    "**Важно:**\n",
    "\n",
    "* Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    "* Если товар не встречался в обучающей выборке, его популярность равна 0.  \n",
    "* Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "* Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и k в recall@k / precision@k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a8512b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6,7,8;', '13,14,15;', '22,23;', '28,29,30,31,32,33;', '40,41;']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"test.txt\", \"r\")\n",
    "test = f.read().splitlines() \n",
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd8a0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,1,2,3,4,5;',\n",
       " '9,10,11,9,11,12,9,11;',\n",
       " '16,17,18,19,20,21;',\n",
       " '24,25,26,27,24;',\n",
       " '34,35,36,34,37,35,36,37,38,39,38,39;']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"train.txt\", \"r\")\n",
    "train = f.read().splitlines() \n",
    "train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa69bcb",
   "metadata": {},
   "source": [
    "# Task №1\n",
    "На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c992dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation_old(path):\n",
    "    f = open(path, \"r\")\n",
    "    text = f.read().splitlines() \n",
    "    data = []\n",
    "\n",
    "    for line in text:\n",
    "        seen, bought = line.split(';')\n",
    "        if bought != '':\n",
    "            data.append([seen.split(\",\"), bought.split(\",\")])\n",
    "        else: \n",
    "            data.append([seen.split(\",\"), []])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37ada799",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_preparation_old(\"test.txt\")\n",
    "train = data_preparation_old(\"train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76bfff88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique_id(data, n):\n",
    "    id_unique = {}\n",
    "    for i in range(len(data)):\n",
    "        for id_value in (data[:][i])[n]:\n",
    "            if id_value not in id_unique:\n",
    "                id_unique.update({id_value: 0})\n",
    "            else:\n",
    "                id_unique.update({id_value: id_unique.get(id_value)+1})\n",
    "    return id_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ecbafdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#id_seen = unique_id(test, 0)\n",
    "#id_bought = unique_id(test, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc804af",
   "metadata": {},
   "source": [
    "----\n",
    "# 1\n",
    "Каждая строчка в файлах - сессия. Читаем файлы построчно, укладываем данные о сессии в словарь с двумя полями: viewed и purchased. Значение в каждом поле - массив соответствующих id-шников. Все такие словари-сессии укладываем в свой массив для каждого файла, т.е. файл теперь представлен набором сессий, а сессия - словарем из двух массивов id-шников."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fa8c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(path):\n",
    "    f = open(path, \"r\")\n",
    "    text = f.read().splitlines() \n",
    "    data = []\n",
    "\n",
    "    for line in text:\n",
    "        seen, bought = line.split(';')\n",
    "\n",
    "        if bought != '':\n",
    "            sess = {\"seen\" : seen.split(\",\") ,\"bought\" : bought.split(\",\")}\n",
    "        else: \n",
    "            sess = {\"seen\" : seen.split(\",\"), \"bought\" : []}\n",
    "        data.append(sess)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3206903",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_preparation(\"test.txt\")\n",
    "train = data_preparation(\"train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8eef7",
   "metadata": {},
   "source": [
    "# Task №2\n",
    "Реализуйте два алгоритма рекомендаций:\n",
    "\n",
    "* сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    "* сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    "\n",
    "## 2\n",
    "Создаем два Counter'а, для viewed и purchased, в цикле скармливаем им id-шники из сессий файла train. Удобно скармливать сразу массив id-шников каждой сессии c помощью метода Counter.update. Counter крут еще и тем, что выдает 0 по умолчанию, т.е. когда к нему обращаются по ключу, которого в нем нет. Именно такое поведение и нужно в задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b03f40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency(data):\n",
    "    counter_seen = collections.Counter()\n",
    "    counter_bought = collections.Counter()\n",
    "    for sess in data:\n",
    "        counter_seen.update(sess.get(\"seen\"))\n",
    "        counter_bought.update(sess.get(\"bought\"))\n",
    "    return counter_seen, counter_bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ded0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_seen, counter_bought = calculate_frequency(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344c862",
   "metadata": {},
   "source": [
    "## 3\n",
    "Теперь можно удалить сессии, у которых массив purchased - пустой. Не .dropna, но тоже элементарно. А можно не удалять из самих выборок, а удалять из рассмотрения при расчете метрик, я так сделал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77d237d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dataset(data):\n",
    "    data_clear = []\n",
    "    for sess in data:\n",
    "        if sess.get(\"bought\") != []:\n",
    "            data_clear.append(sess)\n",
    "    return data_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "de0f206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = clear_dataset(train)\n",
    "test = clear_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809329f1",
   "metadata": {},
   "source": [
    "## 4 \n",
    "Теперь пишем функцию для сортировки viewed id-шников сессии, но тут можно обойтись без сложного ключа сортировки. Удаляем дублирующиеся id, сохраняя их изначальный порядок. Например, вот так: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c3e2fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ids = list(collections.OrderedDict.fromkeys(train[2].get(\"seen\")))\n",
    "#sorted(ids, key=lambda x: counter_seen.keys()) #, reversed=True\n",
    "#ids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eda3931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recommendations(data, counter_seen):\n",
    "    rec_arr = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        rec_dict = {}\n",
    "        ids = data[i].get(\"seen\")\n",
    "        ids = list(set(ids))\n",
    "\n",
    "        for id_value in ids:\n",
    "            rec_dict.update({id_value: counter_seen.setdefault(id_value, 0)})\n",
    "        rec_arr.append(collections.Counter(rec_dict).most_common())\n",
    "    return rec_arr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "550b618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_arr = build_recommendations(test, counter_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9249340",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "rec_arr = []\n",
    "\n",
    "for i in range(len(test)):\n",
    "    rec_dict = {}\n",
    "    ids = test[i].get(\"seen\")\n",
    "    ids = list(set(ids))\n",
    "    \n",
    "    for id_value in ids:\n",
    "        rec_dict.update({id_value: counter_seen.setdefault(id_value, 0)})\n",
    "    rec_arr.append(collections.Counter(rec_dict).most_common())\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8dc8b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_arr[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f34336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collections.Counter(rec_dict).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d4190",
   "metadata": {},
   "source": [
    "Теперь можно сортировать просто по частоте id-шника:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82093721",
   "metadata": {},
   "source": [
    "# Task №3\n",
    "Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие?           Обратите внимание на различие качества на обучающей и тестовой           выборке в случае рекомендаций по частотам покупки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710e641",
   "metadata": {},
   "source": [
    "Recall: Берем отсортированные в п.3 уникальные id в рамках сессии, обрезаем на k. Если массив оказался <k, то он таковым и остается.Ищем пересечение между этим массивом и массивом покупок в рамках текущей сессии. Делим на количество покупок в рамках текущей сессии\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1315e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(k, rec_arr, sess_dict):\n",
    "    precision = np.zeros((len(rec_arr), 1))\n",
    "    recall = np.zeros((len(rec_arr), 1))\n",
    "    for i in range(len(rec_arr)):\n",
    "        sess_bought = rec_arr[i][:k]\n",
    "        bought_id = [int(tup[0]) for tup in sess_bought]\n",
    "        counter = 0\n",
    "\n",
    "        ids = sess_dict[i].get(\"bought\")\n",
    "        \n",
    "\n",
    "        #print(bought_id, ids, len(bought_id),\"\\n\")\n",
    "\n",
    "        for id_value in ids:\n",
    "            id_value = int(id_value)\n",
    "            if id_value in bought_id:\n",
    "                counter += 1\n",
    "            #print(counter)\n",
    "        precision[i, 0] = counter /k\n",
    "        recall[i, 0] = counter / len(bought_id)\n",
    "        #print(counter, precision[i, 0], recall[i, 0])\n",
    "        #precision += counter /k\n",
    "        #recall += counter / len(bought_id)\n",
    "        \n",
    "    precision = np.mean(precision)#precision/ len(rec_arr) \n",
    "    recall = np.mean(recall) #recall/len(rec_arr)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95baa162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_to_file(filename, ar1, ap1, ar5, ap5):\n",
    "    f=open(filename,'w')\n",
    "    f.write(str(round(ar1,2))+\" \")\n",
    "    f.write(str(round(ap1,2))+\" \")\n",
    "    f.write(str(round(ar5,2))+\" \")\n",
    "    f.write(str(round(ap5,2))+\" \")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d1220e",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision_5, recall_5 = metrics(5, rec_arr, test)\n",
    "precision_1, recall_1 = metrics(5, rec_arr, test)\n",
    "print(precision_5, recall_5, precision_1, recall_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531762c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "precision = 0\n",
    "recall = 0\n",
    "for i in range(len(rec_arr)):\n",
    "    sess_bought = rec_arr[i][:k]\n",
    "    bought_id = [int(tup[0]) for tup in sess_bought]\n",
    "    counter = 0\n",
    "\n",
    "    ids = test[i].get(\"bought\")\n",
    "\n",
    "    #print(bought_id, ids, len(bought_id),\"\\n\")\n",
    "    \n",
    "    for id_value in ids:\n",
    "        id_value = int(id_value)\n",
    "        if id_value in bought_id:\n",
    "            counter += 1\n",
    "        #print(counter)\n",
    "    precision += counter /k\n",
    "    recall += counter / len(bought_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ea5e5",
   "metadata": {},
   "source": [
    "Precision: Берем отсортированные в п.3 уникальные id в рамках сессии, обрезаем на k.  Если массив оказался <k, то он таковым и остается.Ищем пересечение между этим массивом и массивом покупок в рамках текущей сессии. Делим на k просто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abf8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(filename):\n",
    "    # 1\n",
    "    test = data_preparation(\"test.txt\")\n",
    "    train = data_preparation(\"train.txt\")\n",
    "\n",
    "    # 2\n",
    "    counter_seen, counter_bought = calculate_frequency(train)\n",
    "\n",
    "    # 3\n",
    "    train = clear_dataset(train)\n",
    "    test = clear_dataset(test)\n",
    "\n",
    "    # 4\n",
    "    rec_arr = build_recommendations(train, counter_seen)\n",
    "\n",
    "    # 5\n",
    "\n",
    "    precision_5, recall_5 = metrics(5, rec_arr, train)\n",
    "    precision_1, recall_1 = metrics(1, rec_arr, train)\n",
    "    print(recall_1, precision_1, recall_5, precision_5)\n",
    "    # 6 \n",
    "    metric_to_file(filename, recall_1, precision_1, recall_5, precision_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa8c507",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(\"answer_1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba182e",
   "metadata": {},
   "source": [
    "# 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36356037",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_preparation(\"test.txt\")\n",
    "train = data_preparation(\"train.txt\")\n",
    "\n",
    "# 2\n",
    "counter_seen, counter_bought = calculate_frequency(train)\n",
    "len(counter_seen)\n",
    "\n",
    "# 3\n",
    "train = clear_dataset(train)\n",
    "test = clear_dataset(test)\n",
    "\n",
    "# 4\n",
    "rec_arr = build_recommendations(test, counter_bought)\n",
    "\n",
    "# 5\n",
    "\n",
    "precision_5, recall_5 = metrics(5, rec_arr, train)\n",
    "precision_1, recall_1 = metrics(1, rec_arr, train)\n",
    "print(recall_1, precision_1, recall_5, precision_5)\n",
    "# 6 \n",
    "metric_to_file(\"answer_2.txt\", recall_1, precision_1, recall_5, precision_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c551b",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f0dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_preparation(\"test.txt\")\n",
    "train = data_preparation(\"train.txt\")\n",
    "\n",
    "# 2\n",
    "counter_seen, counter_bought = calculate_frequency(train)\n",
    "\n",
    "# 3\n",
    "train = clear_dataset(train)\n",
    "test = clear_dataset(test)\n",
    "\n",
    "# 4\n",
    "rec_arr = build_recommendations(train, counter_seen)\n",
    "\n",
    "# 5\n",
    "\n",
    "precision_5, recall_5 = metrics(5, rec_arr, test)\n",
    "precision_1, recall_1 = metrics(1, rec_arr, test)\n",
    "print(recall_1, precision_1, recall_5, precision_5)\n",
    "# 6 \n",
    "metric_to_file(\"answer_3.txt\", recall_1, precision_1, recall_5, precision_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f587f564",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc4ab16",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_preparation(\"test.txt\")\n",
    "train = data_preparation(\"train.txt\")\n",
    "\n",
    "# 2\n",
    "counter_seen, counter_bought = calculate_frequency(train)\n",
    "\n",
    "# 3\n",
    "train = clear_dataset(train)\n",
    "test = clear_dataset(test)\n",
    "\n",
    "# 4\n",
    "rec_arr = build_recommendations(train, counter_bought)\n",
    "\n",
    "# 5\n",
    "\n",
    "precision_5, recall_5 = metrics(5, rec_arr, test)\n",
    "precision_1, recall_1 = metrics(1, rec_arr, test)\n",
    "print(recall_1, precision_1, recall_5, precision_5)\n",
    "# 6 \n",
    "metric_to_file(\"answer_4.txt\", recall_1, precision_1, recall_5, precision_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91062179",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
