{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23504409",
   "metadata": {},
   "source": [
    "# Programming Assignment: \n",
    "\n",
    "\n",
    "1. На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)\n",
    "2. Реализуйте два алгоритма рекомендаций:\n",
    "\n",
    "    сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    "    сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    "\n",
    "3. Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие?           Обратите внимание на различие качества на обучающей и тестовой           выборке в случае рекомендаций по частотам покупки.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0d1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import linalg\n",
    "import collections\n",
    "\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f7d67",
   "metadata": {},
   "source": [
    "\n",
    "**Входные данные**\n",
    "\n",
    "Вам дается две выборки с пользовательскими сессиями - id-шниками просмотренных и id-шниками купленных товаров. Одна выборка будет использоваться для обучения (оценки популярностей товаров), а другая - для теста.\n",
    "\n",
    "В файлах записаны сессии по одной в каждой строке. Формат сессии: id просмотренных товаров через , затем идёт ; после чего следуют id купленных товаров (если такие имеются), разделённые запятой. Например, 1,2,3,4; или 1,2,3,4;5,6.\n",
    "\n",
    "Гарантируется, что среди id купленных товаров все различные.\n",
    "\n",
    "**Важно:**\n",
    "\n",
    "* Сессии, в которых пользователь ничего не купил, исключаем из оценки качества.\n",
    "* Если товар не встречался в обучающей выборке, его популярность равна 0.  \n",
    "* Рекомендуем разные товары. И их число должно быть не больше, чем количество различных просмотренных пользователем товаров.\n",
    "* Рекомендаций всегда не больше, чем минимум из двух чисел: количество просмотренных пользователем товаров и k в recall@k / precision@k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80a8512b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['6,7,8;', '13,14,15;', '22,23;', '28,29,30,31,32,33;', '40,41;']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"test.txt\", \"r\")\n",
    "test = f.read().splitlines() \n",
    "test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd8a0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0,1,2,3,4,5;',\n",
       " '9,10,11,9,11,12,9,11;',\n",
       " '16,17,18,19,20,21;',\n",
       " '24,25,26,27,24;',\n",
       " '34,35,36,34,37,35,36,37,38,39,38,39;']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = open(\"train.txt\", \"r\")\n",
    "train = f.read().splitlines() \n",
    "train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa69bcb",
   "metadata": {},
   "source": [
    "# Task №1\n",
    "На обучении постройте частоты появления id в просмотренных и в купленных (id может несколько раз появляться в просмотренных, все появления надо учитывать)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc804af",
   "metadata": {},
   "source": [
    "----\n",
    "# 1\n",
    "Каждая строчка в файлах - сессия. Читаем файлы построчно, укладываем данные о сессии в словарь с двумя полями: viewed и purchased. Значение в каждом поле - массив соответствующих id-шников. Все такие словари-сессии укладываем в свой массив для каждого файла, т.е. файл теперь представлен набором сессий, а сессия - словарем из двух массивов id-шников."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2fa8c1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_preparation(path):\n",
    "    f = open(path, \"r\")\n",
    "    text = f.read().splitlines() \n",
    "    data = []\n",
    "\n",
    "    for line in text:\n",
    "        seen, bought = line.split(';')\n",
    "\n",
    "        if bought != '':\n",
    "            sess = {\"seen\" : seen.split(\",\") ,\"bought\" : bought.split(\",\")}\n",
    "        else: \n",
    "            sess = {\"seen\" : seen.split(\",\"), \"bought\" : []}\n",
    "        data.append(sess)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3206903",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = data_preparation(\"test.txt\")\n",
    "train = data_preparation(\"train.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f8eef7",
   "metadata": {},
   "source": [
    "# Task №2\n",
    "Реализуйте два алгоритма рекомендаций:\n",
    "\n",
    "* сортировка просмотренных id по популярности (частота появления в просмотренных),\n",
    "* сортировка просмотренных id по покупаемости (частота появления в покупках).\n",
    "\n",
    "## 2\n",
    "Создаем два Counter'а, для viewed и purchased, в цикле скармливаем им id-шники из сессий файла train. Удобно скармливать сразу массив id-шников каждой сессии c помощью метода Counter.update. Counter крут еще и тем, что выдает 0 по умолчанию, т.е. когда к нему обращаются по ключу, которого в нем нет. Именно такое поведение и нужно в задании."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b03f40f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_frequency(data):\n",
    "    counter_seen = collections.Counter()\n",
    "    counter_bought = collections.Counter()\n",
    "    for sess in data:\n",
    "        counter_seen.update(sess.get(\"seen\"))\n",
    "        counter_bought.update(sess.get(\"bought\"))\n",
    "    return counter_seen, counter_bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ded0d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter_seen, counter_bought = calculate_frequency(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b344c862",
   "metadata": {},
   "source": [
    "## 3\n",
    "Теперь можно удалить сессии, у которых массив purchased - пустой. Не .dropna, но тоже элементарно. А можно не удалять из самих выборок, а удалять из рассмотрения при расчете метрик, я так сделал."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77d237d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_dataset(data):\n",
    "    data_clear = []\n",
    "    for sess in data:\n",
    "        if sess.get(\"bought\") != []:\n",
    "            data_clear.append(sess)\n",
    "    return data_clear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "de0f206e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = clear_dataset(train)\n",
    "test = clear_dataset(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809329f1",
   "metadata": {},
   "source": [
    "## 4 \n",
    "Теперь пишем функцию для сортировки viewed id-шников сессии, но тут можно обойтись без сложного ключа сортировки. Удаляем дублирующиеся id, сохраняя их изначальный порядок.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2eda3931",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_recommendations(data, counter_seen):\n",
    "    rec_arr = []\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        rec_dict = {}\n",
    "        ids = data[i].get(\"seen\")\n",
    "        ids = list(set(ids))\n",
    "\n",
    "        for id_value in ids:\n",
    "            rec_dict.update({id_value: counter_seen.setdefault(id_value, 0)})\n",
    "        rec_arr.append(collections.Counter(rec_dict).most_common())\n",
    "    return rec_arr "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550b618a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec_arr = build_recommendations(test, counter_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8dc8b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('63', 6), ('61', 2), ('68', 2), ('66', 2), ('59', 1), ('69', 0), ('70', 0)],\n",
       " [('158', 641), ('162', 318), ('160', 92), ('159', 81), ('161', 74)],\n",
       " [('204', 396), ('202', 66), ('203', 19), ('200', 18), ('201', 12)],\n",
       " [('371', 9), ('372', 5)],\n",
       " [('422', 60)]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rec_arr[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d4190",
   "metadata": {},
   "source": [
    "Теперь можно сортировать просто по частоте id-шника:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82093721",
   "metadata": {},
   "source": [
    "# Task №3\n",
    "Для данных алгоритмов выпишите через пробел AverageRecall@1, AveragePrecision@1, AverageRecall@5, AveragePrecision@5 на обучающей и тестовых выборках, округляя до 2 знака после запятой. Это будут ваши ответы в этом задании. Посмотрите, как они соотносятся друг с другом. Где качество получилось выше? Значимо ли это различие?           Обратите внимание на различие качества на обучающей и тестовой           выборке в случае рекомендаций по частотам покупки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2710e641",
   "metadata": {},
   "source": [
    "Recall: Берем отсортированные в п.3 уникальные id в рамках сессии, обрезаем на k. Если массив оказался <k, то он таковым и остается.Ищем пересечение между этим массивом и массивом покупок в рамках текущей сессии. Делим на количество покупок в рамках текущей сессии\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1315e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(k, rec_arr, sess_dict):\n",
    "    precision = np.zeros((len(rec_arr), 1))\n",
    "    recall = np.zeros((len(rec_arr), 1))\n",
    "    for i in range(len(rec_arr)):\n",
    "        sess_bought = rec_arr[i][:k]\n",
    "        bought_id = [int(tup[0]) for tup in sess_bought]\n",
    "        counter = 0\n",
    "\n",
    "        ids = sess_dict[i].get(\"bought\")\n",
    "        \n",
    "\n",
    "        #print(bought_id, ids, len(bought_id),\"\\n\")\n",
    "\n",
    "        for id_value in ids:\n",
    "            id_value = int(id_value)\n",
    "            if id_value in bought_id:\n",
    "                counter += 1\n",
    "            #print(counter)\n",
    "        precision[i, 0] = counter /k\n",
    "        recall[i, 0] = counter / len(ids)\n",
    "        #print(ids, bought_id,\"\\t\", counter, precision[i, 0], recall[i, 0])\n",
    "        #precision += counter /k\n",
    "        #recall += counter / len(bought_id)\n",
    "        \n",
    "    precision = np.mean(precision)#precision/ len(rec_arr) \n",
    "    recall = np.mean(recall) #recall/len(rec_arr)\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95baa162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metric_to_file(filename, ar1, ap1, ar5, ap5):\n",
    "    f=open(filename,'w')\n",
    "    f.write(str(round(ar1,2))+\" \")\n",
    "    f.write(str(round(ap1,2))+\" \")\n",
    "    f.write(str(round(ar5,2))+\" \")\n",
    "    f.write(str(round(ap5,2))+\" \")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "531762c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "precision = 0\n",
    "recall = 0\n",
    "for i in range(len(rec_arr)):\n",
    "    sess_bought = rec_arr[i][:k]\n",
    "    bought_id = [int(tup[0]) for tup in sess_bought]\n",
    "    counter = 0\n",
    "\n",
    "    ids = test[i].get(\"bought\")\n",
    "\n",
    "    #print(bought_id, ids, len(bought_id),\"\\n\")\n",
    "    \n",
    "    for id_value in ids:\n",
    "        id_value = int(id_value)\n",
    "        if id_value in bought_id:\n",
    "            counter += 1\n",
    "        #print(counter)\n",
    "    precision += counter /k\n",
    "    recall += counter / len(bought_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552ea5e5",
   "metadata": {},
   "source": [
    "Precision: Берем отсортированные в п.3 уникальные id в рамках сессии, обрезаем на k.  Если массив оказался <k, то он таковым и остается.Ищем пересечение между этим массивом и массивом покупок в рамках текущей сессии. Делим на k просто"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1abf8d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(filename):\n",
    "    # 1\n",
    "    test = data_preparation(\"test.txt\")\n",
    "    train = data_preparation(\"train.txt\")\n",
    "\n",
    "    # 2\n",
    "    counter_seen, counter_bought = calculate_frequency(train)\n",
    "\n",
    "    # 3\n",
    "    train = clear_dataset(train)\n",
    "    test = clear_dataset(test)\n",
    "\n",
    "    # 4\n",
    "    rec_arr = build_recommendations(train, counter_seen)\n",
    "\n",
    "    # 5\n",
    "\n",
    "    precision_5, recall_5 = metrics(5, rec_arr, train)\n",
    "    precision_1, recall_1 = metrics(1, rec_arr, train)\n",
    "    print(round(recall_1, 2), round(precision_1, 2), round(recall_5, 2), round(precision_5, 2))\n",
    "    # 6 \n",
    "    metric_to_file(filename, recall_1, precision_1, recall_5, precision_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fa8c507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44 0.51 0.82 0.21\n"
     ]
    }
   ],
   "source": [
    "summary(\"answer_1.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbba182e",
   "metadata": {},
   "source": [
    "# 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "36356037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.68 0.79 0.93 0.25\n"
     ]
    }
   ],
   "source": [
    "test = data_preparation(\"test.txt\")\n",
    "train = data_preparation(\"train.txt\")\n",
    "\n",
    "# 2\n",
    "counter_seen, counter_bought = calculate_frequency(train)\n",
    "len(counter_seen)\n",
    "\n",
    "# 3\n",
    "train = clear_dataset(train)\n",
    "test = clear_dataset(test)\n",
    "\n",
    "# 4\n",
    "rec_arr = build_recommendations(train, counter_bought)\n",
    "\n",
    "# 5\n",
    "\n",
    "precision_5, recall_5 = metrics(5, rec_arr, train)\n",
    "precision_1, recall_1 = metrics(1, rec_arr, train)\n",
    "print(round(recall_1, 2), round(precision_1, 2), round(recall_5, 2), round(precision_5, 2))\n",
    "# 6 \n",
    "metric_to_file(\"answer_2.txt\", recall_1, precision_1, recall_5, precision_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a4c551b",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e0f0dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.67 0.78 0.92 0.25\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test = data_preparation(\"test.txt\")\n",
    "train = data_preparation(\"train.txt\")\n",
    "\n",
    "# 2\n",
    "counter_seen, counter_bought = calculate_frequency(test)\n",
    "\n",
    "# 3\n",
    "train = clear_dataset(train)\n",
    "test = clear_dataset(test)\n",
    "\n",
    "# 4\n",
    "rec_arr = build_recommendations(test, counter_bought)\n",
    "\n",
    "# 5\n",
    "\n",
    "precision_5, recall_5 = metrics(5, rec_arr, test)\n",
    "precision_1, recall_1 = metrics(1, rec_arr, test)\n",
    "print(round(recall_1, 2), round(precision_1, 2), round(recall_5, 2), round(precision_5, 2))\n",
    "# 6 \n",
    "metric_to_file(\"answer_4.txt\", recall_1, precision_1, recall_5, precision_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f587f564",
   "metadata": {},
   "source": [
    "# 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7bc4ab16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43 0.5 0.81 0.21\n"
     ]
    }
   ],
   "source": [
    "test = data_preparation(\"test.txt\")\n",
    "train = data_preparation(\"train.txt\")\n",
    "# 2\n",
    "counter_seen, counter_bought = calculate_frequency(test)\n",
    "\n",
    "# 3\n",
    "train = clear_dataset(train)\n",
    "test = clear_dataset(test)\n",
    "\n",
    "# 4\n",
    "rec_arr = build_recommendations(test, counter_seen)\n",
    "\n",
    "# 5\n",
    "\n",
    "precision_5, recall_5 = metrics(5, rec_arr, test)\n",
    "precision_1, recall_1 = metrics(1, rec_arr, test)\n",
    "print(round(recall_1, 2), round(precision_1, 2), round(recall_5, 2), round(precision_5, 2))\n",
    "# 6 \n",
    "metric_to_file(\"answer_3.txt\", recall_1, precision_1, recall_5, precision_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
