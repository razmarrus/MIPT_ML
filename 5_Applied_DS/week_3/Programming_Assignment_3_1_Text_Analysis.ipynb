{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23504409",
   "metadata": {},
   "source": [
    "# Programming Assignment: Spam Filter\n",
    "\n",
    "1. Загрузите датасет. Описание датасета можно посмотреть здесь.\n",
    "\n",
    "2. Считайте датасет в Python (можете сразу грузить все в память, выборка небольшая), выясните, что используется в качестве разделителей и как проставляются метки классов.\n",
    "\n",
    "3. Подготовьте для дальнейшей работы два списка: список текстов в порядке их следования в датасете и список соответствующих им меток классов. В качестве метки класса используйте 1 для спама и 0 для \"не спама\".\n",
    "\n",
    "4. Используя sklearn.feature_extraction.text.CountVectorizer со стандартными настройками, получите из списка текстов матрицу признаков X.\n",
    "\n",
    "5. Оцените качество классификации текстов с помощью LogisticRegression() с параметрами по умолчанию, используя sklearn.cross_validation.cross_val_score и посчитав среднее арифметическое качества на отдельных fold'ах. Установите random_state=2. Параметр cv задайте равным 10. В качестве метрики качества используйте f1-меру. Получившееся качество - один из ответов, которые потребуются при сдаче задания. Ответ округлить до 1 знака после запятой.\n",
    "\n",
    "6. А теперь обучите классификатор на всей выборке и спрогнозируйте с его помощью класс для следующих сообщений. Прогнозы классификатора (0 - не спам, 1 - спам), записанные через пробел, будут ответом в одном из вопросов ниже.\n",
    "```\n",
    " \"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\"\n",
    "\"FreeMsg: Txt: claim your reward of 3 hours talk time\"\n",
    "\"Have you visited the last lecture on physics?\"\n",
    "\"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99\"\n",
    "\"Only 99\"\n",
    "```\n",
    "\n",
    "7. Задайте в CountVectorizer параметр ngram_range=(2,2), затем ngram_range=(3,3), затем ngram_range=(1,3). Во всех трех случаях измерьте получившееся в кросс-валидации значение f1-меры, округлите до второго знака после точки, и выпишете результаты через пробел в том же порядке. В данном эксперименте мы пробовали добавлять в признаки n-граммы для разных диапазонов n - только биграммы, только триграммы, и, наконец, все вместе - униграммы, биграммы и триграммы. Обратите внимание, что статистики по биграммам и триграммам намного меньше, поэтому классификатор только на них работает хуже. В то же время это не ухудшает результат сколько-нибудь существенно, если добавлять их вместе с униграммами, т.к. за счет регуляризации линейный классификатор не склонен сильно переобучаться на этих признаках.\n",
    "\n",
    "8. Повторите аналогичный п.7 эксперимент, используя вместо логистической регрессии MultinomialNB(). Обратите внимание, насколько сильнее (по сравнению с линейным классификатором) наивный Байес страдает от нехватки статистики по биграммам и триграммам.\n",
    "\n",
    " По какой-то причине  обучение наивного байесовского классификатора через Pipeline происходит с ошибкой. Чтобы получить правильный ответ, отдельно  посчитайте частоты слов и обучите классификатор.  \n",
    "\n",
    "9. Попробуйте использовать в логистической регрессии в качестве признаков Tf*idf из TfidfVectorizer на униграммах. Повысилось или понизилось качество на кросс-валидации по сравнению с CountVectorizer на униграммах? (напишите в файле с ответом 1, если повысилось, -1, если понизилось, и 0, если изменилось не более чем на 0.01). Обратите внимание, что результат перехода к tf*idf не всегда будет таким - если вы наблюдаете какое-то явление на одном датасете, не надо сразу же его обобщать на любые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e0d1c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c291c96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9f7d67",
   "metadata": {},
   "source": [
    "# Task №1\n",
    "Загрузите датасет. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80a8512b",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"SMSSpamCollection.txt\", \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10876d6d",
   "metadata": {},
   "source": [
    "# Task №2\n",
    "Считайте датасет в Python (можете сразу грузить все в память, выборка небольшая), выясните, что используется в качестве разделителей и как проставляются метки классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "349c4f32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham\\tGo until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 'ham\\tOk lar... Joking wif u oni...',\n",
       " \"spam\\tFree entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       " 'ham\\tU dun say so early hor... U c already then say...',\n",
       " \"ham\\tNah I don't think he goes to usf, he lives around here though\",\n",
       " \"spam\\tFreeMsg Hey there darling it's been 3 week's now and no word back! I'd like some fun you up for it still? Tb ok! XxX std chgs to send, Â£1.50 to rcv\",\n",
       " 'ham\\tEven my brother is not like to speak with me. They treat me like aids patent.',\n",
       " \"ham\\tAs per your request 'Melle Melle (Oru Minnaminunginte Nurungu Vettam)' has been set as your callertune for all Callers. Press *9 to copy your friends Callertune\",\n",
       " 'spam\\tWINNER!! As a valued network customer you have been selected to receivea Â£900 prize reward! To claim call 09061701461. Claim code KL341. Valid 12 hours only.',\n",
       " 'spam\\tHad your mobile 11 months or more? U R entitled to Update to the latest colour mobiles with camera for Free! Call The Mobile Update Co FREE on 08002986030']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = f.read().splitlines() \n",
    "text[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84e2b65",
   "metadata": {},
   "source": [
    "# Task №3\n",
    "Подготовьте для дальнейшей работы два списка: список текстов в порядке их следования в датасете и список соответствующих им меток классов. В качестве метки класса используйте 1 для спама и 0 для \"не спама\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bde495f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0 if 'ham' in line else 1 for line in text])\n",
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1649dabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go until jurong point, crazy.. Available only in bugis n great world la e buffet... Cine there got amore wat...',\n",
       " 'Ok lar... Joking wif u oni...',\n",
       " \"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\",\n",
       " 'U dun say so early hor... U c already then say...',\n",
       " \"Nah I don't think he goes to usf, he lives around here though\"]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [line[4:] if 'ham' in line else line[5:] for line in text]\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30778f7",
   "metadata": {},
   "source": [
    "# Task №4\n",
    "Используя sklearn.feature_extraction.text.CountVectorizer со стандартными настройками, получите из списка текстов матрицу признаков X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08637d0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analyzer': 'word',\n",
       " 'binary': False,\n",
       " 'decode_error': 'strict',\n",
       " 'dtype': numpy.int64,\n",
       " 'encoding': 'utf-8',\n",
       " 'input': 'content',\n",
       " 'lowercase': True,\n",
       " 'max_df': 1.0,\n",
       " 'max_features': None,\n",
       " 'min_df': 1,\n",
       " 'ngram_range': (1, 1),\n",
       " 'preprocessor': None,\n",
       " 'stop_words': None,\n",
       " 'strip_accents': None,\n",
       " 'token_pattern': '(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       " 'tokenizer': None,\n",
       " 'vocabulary': None}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "test = tuple(text)\n",
    "X = vectorizer.fit_transform(text)\n",
    "\n",
    "vectorizer.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d453374",
   "metadata": {},
   "source": [
    "# Task №5\n",
    "Оцените качество классификации текстов с помощью LogisticRegression() с параметрами по умолчанию, используя sklearn.cross_validation.cross_val_score и посчитав среднее арифметическое качества на отдельных fold'ах. Установите random_state=2. Параметр cv задайте равным 10. В качестве метрики качества используйте f1-меру. Получившееся качество - один из ответов, которые потребуются при сдаче задания. Ответ округлить до 1 знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d27da483",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "score = cross_val_score(model, X, y, cv=10, scoring='f1').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ecbc2590",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer_1.txt', 'w') as f:\n",
    "    ans1 = str(round(score, 1))\n",
    "    f.write(ans1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64ef706e",
   "metadata": {},
   "source": [
    "# Task №6\n",
    "А теперь обучите классификатор на всей выборке и спрогнозируйте с его помощью класс для следующих сообщений:\n",
    "\n",
    "```\n",
    "FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\"\n",
    "\n",
    "\"FreeMsg: Txt: claim your reward of 3 hours talk time\"\n",
    "\n",
    "\"Have you visited the last lecture on physics?\"\n",
    "\n",
    "\"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\"\n",
    "\n",
    "\"Only 99$\"\n",
    "```\n",
    "\n",
    "Прогнозы классификатора (0 - не спам, 1 - спам), записанные через пробел, будут ответом в одном из вопросов ниже."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0231484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [\"FreeMsg: Txt: CALL to No: 86888 & claim your reward of 3 hours talk time to use from your phone now! Subscribe6GB\",\n",
    "\"FreeMsg: Txt: claim your reward of 3 hours talk time\",\n",
    "\"Have you visited the last lecture on physics?\",\n",
    "\"Have you visited the last lecture on physics? Just buy this book and you will have all materials! Only 99$\",\n",
    "\"Only 99$\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d474950",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.array([1, 1, 0, 0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dda77b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('count_vect', CountVectorizer()), ('log_reg', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "615cac0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(text, y)\n",
    "test_pred = pipeline.predict(X_test)\n",
    "test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c2de1d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer_2.txt', 'w') as f:\n",
    "    ans2 = ' '.join(map(str, test_pred))\n",
    "    f.write(ans2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3144c5d9",
   "metadata": {},
   "source": [
    "# Task №7\n",
    "\n",
    "Задайте в CountVectorizer параметр ngram_range=(2,2), затем ngram_range=(3,3), затем ngram_range=(1,3). Во всех трех случаях измерьте получившееся в кросс-валидации значение f1-меры, округлите до второго знака после точки, и выпишете результаты через пробел в том же порядке. В данном эксперименте мы пробовали добавлять в признаки n-граммы для разных диапазонов n - только биграммы, только триграммы, и, наконец, все вместе - униграммы, биграммы и триграммы. Обратите внимание, что статистики по биграммам и триграммам намного меньше, поэтому классификатор только на них работает хуже. В то же время это не ухудшает результат сколько-нибудь существенно, если добавлять их вместе с униграммами, т.к. за счет регуляризации линейный классификатор не склонен сильно переобучаться на этих признаках.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "102dacd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_list = [(2, 2), (3,3), (1,3)]\n",
    "scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "861dec56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ngram range(2, 2) score is 0.8149627290910922\n",
      "for ngram range(3, 3) score is 0.7214250187862131\n",
      "for ngram range(1, 3) score is 0.9248620087597395\n"
     ]
    }
   ],
   "source": [
    "for ngram in ngram_list:\n",
    "    pipeline = Pipeline([('count_vect', CountVectorizer(ngram_range=ngram)), ('log_reg', LogisticRegression())])\n",
    "    scores.append(cross_val_score(pipeline, text, y, cv=10, scoring='f1').mean())\n",
    "    print(f'for ngram range{ngram} score is {scores[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25976c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer_3.txt', 'w') as f:\n",
    "    ans3 = ' '.join(map(str, scores))\n",
    "    f.write(ans3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e054c",
   "metadata": {},
   "source": [
    "# Task №8\n",
    "Повторите аналогичный п.7 эксперимент, используя вместо логистической регрессии MultinomialNB(). Обратите внимание, насколько сильнее (по сравнению с линейным классификатором) наивный Байес страдает от нехватки статистики по биграммам и триграммам.\n",
    "\n",
    " По какой-то причине  обучение наивного байесовского классификатора через Pipeline происходит с ошибкой. Чтобы получить правильный ответ, отдельно  посчитайте частоты слов и обучите классификатор.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "785cf1ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for ngram range(2, 2) score is 0.6413349322862512\n",
      "for ngram range(3, 3) score is 0.37534612137637324\n",
      "for ngram range(1, 3) score is 0.8844158878674179\n"
     ]
    }
   ],
   "source": [
    "scores_multinomial = []\n",
    "for ngram in ngram_list:\n",
    "    pipeline = Pipeline([('mn_nb', MultinomialNB())])\n",
    "    scores_multinomial.append(cross_val_score(pipeline,  CountVectorizer(ngram_range=ngram).fit_transform(text), y, cv=10, scoring='f1').mean())\n",
    "    print(f'for ngram range{ngram} score is {scores_multinomial[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88900d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer_4.txt', 'w') as f:\n",
    "    ans4 = ' '.join(map(str, scores_multinomial))\n",
    "    f.write(ans4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeca636",
   "metadata": {},
   "source": [
    "# Task №9\n",
    "Попробуйте использовать в логистической регрессии в качестве признаков Tf*idf из TfidfVectorizer на униграммах. Повысилось или понизилось качество на кросс-валидации по сравнению с CountVectorizer на униграммах? (напишите в файле с ответом 1, если повысилось, -1, если понизилось, и 0, если изменилось не более чем на 0.01). Обратите внимание, что результат перехода к tf*idf не всегда будет таким - если вы наблюдаете какое-то явление на одном датасете, не надо сразу же его обобщать на любые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f0fb47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline([('tf_vect', TfidfVectorizer()), ('log_reg', LogisticRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dde6b516",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23649276363140115"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans_5 = cross_val_score(pipeline, text, y, cv=10, scoring='f1').mean() - scores_multinomial[0]\n",
    "ans_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b61417ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('answer_5.txt', 'w') as f:\n",
    "    if np.absolute(ans_5) < 0.01:        \n",
    "        ans_5 = '0'\n",
    "    elif ans_5 > 0: \n",
    "        ans_5 = '1'\n",
    "    else:\n",
    "        ans_5 = '-1'\n",
    "    \n",
    "    f.write(ans_5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
